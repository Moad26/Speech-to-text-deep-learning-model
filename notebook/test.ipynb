{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf6faed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from torchaudio.datasets import LIBRISPEECH\n",
    "\n",
    "dataset = LIBRISPEECH(root='../input', url='test-clean', download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0efa44",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m waveform, sample_rate, transcript, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWaveform shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, waveform\u001b[38;5;241m.\u001b[39mshape) \n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample rate:\u001b[39m\u001b[38;5;124m\"\u001b[39m, sample_rate)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\" waveform, sample_rate, transcript, _, _, _ = dataset[0]\n",
    "\n",
    "print(\"Waveform shape:\", waveform.shape) \n",
    "print(\"Sample rate:\", sample_rate)\n",
    "print(\"Transcript:\", transcript) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9af0c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio.transforms as T\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b47420",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TARGET_SAMPLE_RATE = 16000\n",
    "TARGET_NUM_CHANNELS = 2\n",
    "TARGET_DURATION = 5 \n",
    "TARGET_NUM_SAMPLES = TARGET_SAMPLE_RATE * TARGET_DURATION \"\"\"\n",
    "\n",
    "def preprocess_waveform(waveform, sample_rate):\n",
    "    \"\"\"\n",
    "    Resample output for original sample to 16000\n",
    "    Convert to stereo\n",
    "    pad or truncate th fixed duration\n",
    "    Input shape: [channels, num_samples]\n",
    "    Output shape: [2, TARGET_NUM_SAMPLES]\n",
    "    \"\"\"\n",
    "    if waveform.shape[0] == 1:\n",
    "        waveform = waveform.repeat(TARGET_NUM_CHANNELS, 1)\n",
    "\n",
    "    if sample_rate != TARGET_SAMPLE_RATE:\n",
    "        resampler = T.Resample(orig_freq=sample_rate, new_freq=TARGET_SAMPLE_RATE)\n",
    "        waveform = torch.stack([\n",
    "            resampler(wf.unsqueeze(0)).squeeze(0)\n",
    "            for wf in waveform\n",
    "        ])\n",
    "    \n",
    "    if waveform.shape[1] > TARGET_NUM_SAMPLES:\n",
    "        waveform = waveform[:,:TARGET_NUM_SAMPLES]\n",
    "    elif waveform.shape[1] < TARGET_NUM_SAMPLES:\n",
    "        pad_length = TARGET_NUM_SAMPLES - waveform.shape[1]\n",
    "        waveform = torch.nn.functional.pad(waveform, (0, pad_length))  \n",
    "    return waveform  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff503127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def time_shift(waveform, shift_limit=0.2):\n",
    "    \"\"\"moves the entire audio forward or backward slightly in time\"\"\"\n",
    "    shift_amt = int(random.uniform(-shift_limit, shift_limit) * waveform.size(1))\n",
    "    return torch.roll(waveform, shifts=shift_amt, dims=1)\n",
    "def speed_change(waveform, rate):\n",
    "    \"\"\"makes the audio play faster or slower\"\"\"\n",
    "    effects = [['speed', str(rate)], ['rate', '16000']]\n",
    "    waveform, _ = torchaudio.sox_effects.apply_effects_tensor(waveform, 16000, effects)\n",
    "    return waveform\n",
    "def pitch_shift(waveform, n_steps):\n",
    "    \"\"\"changes how high or low the speaker sounds\"\"\"\n",
    "    effects = [['pitch', str(n_steps * 100)], ['rate', '16000']]\n",
    "    waveform, _ = torchaudio.sox_effects.apply_effects_tensor(waveform, 16000, effects)\n",
    "    return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44abd935",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_transform = T.MelSpectrogram(\n",
    "    sample_rate=16000,\n",
    "    n_fft=1024,\n",
    "    hop_length=512,\n",
    "    n_mels=80,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cedb864",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_transform = T.MFCC(\n",
    "    sample_rate=16000,\n",
    "    n_mfcc=13,\n",
    "    melkwargs={\"n_fft\": 1024, \"hop_length\": 512, \"n_mels\": 80}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9276dbdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
