{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68859f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import random\n",
    "class PreprocessedLibriSpeech(Dataset):\n",
    "    def __init__(self, root, url='../test-clean', sample_rate=16000, duration=5, augment=True, shift_limit=0.2, rate=1.2, n_steps=1.2):\n",
    "        self.dataset = torchaudio.datasets.LIBRISPEECH(root=root, url=url, download=False)\n",
    "        self.sample_rate = sample_rate\n",
    "        self.num_samples = sample_rate * duration\n",
    "        self.num_channels = 2\n",
    "        self.augment = augment\n",
    "        self.shift_limit = shift_limit\n",
    "        self.rate = rate\n",
    "        self.n_steps = n_steps\n",
    "\n",
    "        self.mel_transform = T.MelSpectrogram(\n",
    "            sample_rate=16000,\n",
    "            n_fft=1024,\n",
    "            hop_length=512,\n",
    "            n_mels=80,\n",
    "        )\n",
    "\n",
    "        self.mfcc_transform = T.MFCC(\n",
    "            sample_rate=16000,\n",
    "            n_mfcc=13,\n",
    "            melkwargs={\"n_fft\": 1024, \"hop_length\": 512, \"n_mels\": 80}\n",
    "        )\n",
    "        \n",
    "        self.spec_augment = torch.nn.Sequential(\n",
    "            T.FrequencyMasking(freq_mask_param=80),\n",
    "            T.TimeMasking(time_mask_param=80)\n",
    "        ) if augment else torch.nn.Identity()\n",
    "\n",
    "    @staticmethod\n",
    "    def time_shift(waveform, shift_limit):\n",
    "        \"\"\"moves the entire audio forward or backward slightly in time\"\"\"\n",
    "        shift_amt = int(random.uniform(-shift_limit, shift_limit) * waveform.size(1))\n",
    "        return torch.roll(waveform, shifts=shift_amt, dims=1)\n",
    "    @staticmethod\n",
    "    def speed_change(waveform, rate):\n",
    "        \"\"\"makes the audio play faster or slower\"\"\"\n",
    "        effects = [['speed', str(rate)], ['rate', '16000']]\n",
    "        waveform, _ = torchaudio.sox_effects.apply_effects_tensor(waveform, 16000, effects)\n",
    "        return waveform\n",
    "    @staticmethod\n",
    "    def pitch_shift(waveform, n_steps):\n",
    "        \"\"\"changes how high or low the speaker sounds\"\"\"\n",
    "        effects = [['pitch', str(n_steps * 100)], ['rate', '16000']]\n",
    "        waveform, _ = torchaudio.sox_effects.apply_effects_tensor(waveform, 16000, effects)\n",
    "        return waveform\n",
    "    \n",
    "    def raw_augment(self, waveform):\n",
    "        waveform = self.pitch_shift(self.speed_change(self.time_shift(waveform=waveform, shift_limit=self.shift_limit),rate=self.rate),n_steps=self.n_steps)\n",
    "        return waveform\n",
    "\n",
    "    def preprocess_waveform(self,waveform, original_sr):\n",
    "        \"\"\"\n",
    "        Resample output for original sample to 16000\n",
    "        Convert to stereo\n",
    "        pad or truncate th fixed duration\n",
    "        Input shape: [channels, num_samples]\n",
    "        Output shape: [2, TARGET_NUM_SAMPLES]\n",
    "        \"\"\"\n",
    "        if waveform.shape[0] == 1:\n",
    "            waveform = waveform.repeat(self.num_channels, 1)\n",
    "\n",
    "        if original_sr != self.sample_rate:\n",
    "            resampler = T.Resample(orig_freq=original_sr, new_freq=self.sample_rate)\n",
    "            waveform = torch.stack([\n",
    "                resampler(wf.unsqueeze(0)).squeeze(0)\n",
    "                for wf in waveform\n",
    "            ])\n",
    "        \n",
    "        if waveform.shape[1] > self.num_samples:\n",
    "            waveform = waveform[:,:self.num_samples]\n",
    "        elif waveform.shape[1] < self.num_samples:\n",
    "            pad_length = self.num_samples - waveform.shape[1]\n",
    "            waveform = torch.nn.functional.pad(waveform, (0, pad_length))  \n",
    "        return waveform  \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    def __getitem__(self, index):\n",
    "            waveform, sample_rate, transcript, _, _, _ = self.dataset[index]\n",
    "            waveform = self.preprocess_waveform(waveform=waveform, original_sr=sample_rate)\n",
    "            waveform = self.raw_augment(waveform=waveform)\n",
    "            mel_spec  = self.mel_transform(waveform)\n",
    "            mel_spec  = self.spec_augment(mel_spec)\n",
    "            #mel_spec  = self.mfcc_transform(mel_spec)\n",
    "            vocab = list(\"abcdefghijklmnopqrstuvwxyz '\")\n",
    "            char2idx = {c:i+1 for i,c in enumerate(vocab)}\n",
    "            transcript = transcript.lower()\n",
    "            label = torch.tensor([char2idx.get(c,0) for c in transcript])\n",
    "\n",
    "            return mel_spec, label\n",
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
